{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tara3165/NLP-/blob/CompliantAnalysis/Bertopic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fYEv4QyVZkzF",
        "outputId": "051b11ee-1102-4bcc-ae9b-36356c458a78"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive\n"
          ]
        }
      ],
      "source": [
        "cd drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2j9iX4WyRgD1",
        "outputId": "77fe48e4-a6b3-4f16-a23c-98f64b85179d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34mMyDrive\u001b[0m/\n"
          ]
        }
      ],
      "source": [
        "ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KWHuG5VyyAR6",
        "outputId": "eff68558-0cee-45c0-ff53-33a0297bdd41"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting BERTopic\n",
            "  Downloading bertopic-0.16.0-py2.py3-none-any.whl (154 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.1/154.1 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.10/dist-packages (from BERTopic) (1.25.2)\n",
            "Collecting hdbscan>=0.8.29 (from BERTopic)\n",
            "  Downloading hdbscan-0.8.33.tar.gz (5.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting umap-learn>=0.5.0 (from BERTopic)\n",
            "  Downloading umap-learn-0.5.5.tar.gz (90 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.9/90.9 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pandas>=1.1.5 in /usr/local/lib/python3.10/dist-packages (from BERTopic) (1.5.3)\n",
            "Requirement already satisfied: scikit-learn>=0.22.2.post1 in /usr/local/lib/python3.10/dist-packages (from BERTopic) (1.2.2)\n",
            "Requirement already satisfied: tqdm>=4.41.1 in /usr/local/lib/python3.10/dist-packages (from BERTopic) (4.66.2)\n",
            "Collecting sentence-transformers>=0.4.1 (from BERTopic)\n",
            "  Downloading sentence_transformers-2.5.1-py3-none-any.whl (156 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.5/156.5 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: plotly>=4.7.0 in /usr/local/lib/python3.10/dist-packages (from BERTopic) (5.15.0)\n",
            "Collecting cython<3,>=0.27 (from hdbscan>=0.8.29->BERTopic)\n",
            "  Using cached Cython-0.29.37-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (1.9 MB)\n",
            "Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.10/dist-packages (from hdbscan>=0.8.29->BERTopic) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.10/dist-packages (from hdbscan>=0.8.29->BERTopic) (1.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->BERTopic) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->BERTopic) (2023.4)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly>=4.7.0->BERTopic) (8.2.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from plotly>=4.7.0->BERTopic) (24.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.22.2.post1->BERTopic) (3.3.0)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.32.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=0.4.1->BERTopic) (4.38.2)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=0.4.1->BERTopic) (2.2.1+cu121)\n",
            "Requirement already satisfied: huggingface-hub>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=0.4.1->BERTopic) (0.20.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=0.4.1->BERTopic) (9.4.0)\n",
            "Requirement already satisfied: numba>=0.51.2 in /usr/local/lib/python3.10/dist-packages (from umap-learn>=0.5.0->BERTopic) (0.58.1)\n",
            "Collecting pynndescent>=0.5 (from umap-learn>=0.5.0->BERTopic)\n",
            "  Downloading pynndescent-0.5.11-py3-none-any.whl (55 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.8/55.8 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers>=0.4.1->BERTopic) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers>=0.4.1->BERTopic) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers>=0.4.1->BERTopic) (2.31.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers>=0.4.1->BERTopic) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers>=0.4.1->BERTopic) (4.10.0)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.2->umap-learn>=0.5.0->BERTopic) (0.41.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas>=1.1.5->BERTopic) (1.16.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->BERTopic) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->BERTopic) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->BERTopic) (3.1.3)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.11.0->sentence-transformers>=0.4.1->BERTopic)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.11.0->sentence-transformers>=0.4.1->BERTopic)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m41.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.11.0->sentence-transformers>=0.4.1->BERTopic)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.11.0->sentence-transformers>=0.4.1->BERTopic)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.11.0->sentence-transformers>=0.4.1->BERTopic)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.11.0->sentence-transformers>=0.4.1->BERTopic)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.11.0->sentence-transformers>=0.4.1->BERTopic)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.11.0->sentence-transformers>=0.4.1->BERTopic)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.11.0->sentence-transformers>=0.4.1->BERTopic)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu12==2.19.3 (from torch>=1.11.0->sentence-transformers>=0.4.1->BERTopic)\n",
            "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.11.0->sentence-transformers>=0.4.1->BERTopic)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->BERTopic) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence-transformers>=0.4.1->BERTopic)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.99-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m61.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers>=0.4.1->BERTopic) (2023.12.25)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers>=0.4.1->BERTopic) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers>=0.4.1->BERTopic) (0.4.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers>=0.4.1->BERTopic) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers>=0.4.1->BERTopic) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers>=0.4.1->BERTopic) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers>=0.4.1->BERTopic) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers>=0.4.1->BERTopic) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence-transformers>=0.4.1->BERTopic) (1.3.0)\n",
            "Building wheels for collected packages: hdbscan, umap-learn\n",
            "  Building wheel for hdbscan (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for hdbscan: filename=hdbscan-0.8.33-cp310-cp310-linux_x86_64.whl size=3039276 sha256=7f8d1aa521020a1a2cf06008a95b746a91f47e6d6b34dc96681c92d593048d12\n",
            "  Stored in directory: /root/.cache/pip/wheels/75/0b/3b/dc4f60b7cc455efaefb62883a7483e76f09d06ca81cf87d610\n",
            "  Building wheel for umap-learn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for umap-learn: filename=umap_learn-0.5.5-py3-none-any.whl size=86832 sha256=5a3da9edeedfb7ff02caf4bbe2a3d04e0f2d7634a8cbe904b3e952cc218af3dd\n",
            "  Stored in directory: /root/.cache/pip/wheels/3a/70/07/428d2b58660a1a3b431db59b806a10da736612ebbc66c1bcc5\n",
            "Successfully built hdbscan umap-learn\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, cython, nvidia-cusparse-cu12, nvidia-cudnn-cu12, pynndescent, nvidia-cusolver-cu12, hdbscan, umap-learn, sentence-transformers, BERTopic\n",
            "  Attempting uninstall: cython\n",
            "    Found existing installation: Cython 3.0.9\n",
            "    Uninstalling Cython-3.0.9:\n",
            "      Successfully uninstalled Cython-3.0.9\n",
            "Successfully installed BERTopic-0.16.0 cython-0.29.37 hdbscan-0.8.33 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.99 nvidia-nvtx-cu12-12.1.105 pynndescent-0.5.11 sentence-transformers-2.5.1 umap-learn-0.5.5\n",
            "Collecting keybert\n",
            "  Downloading keybert-0.8.4.tar.gz (29 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: sentence-transformers>=0.3.8 in /usr/local/lib/python3.10/dist-packages (from keybert) (2.5.1)\n",
            "Requirement already satisfied: scikit-learn>=0.22.2 in /usr/local/lib/python3.10/dist-packages (from keybert) (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from keybert) (1.25.2)\n",
            "Requirement already satisfied: rich>=10.4.0 in /usr/local/lib/python3.10/dist-packages (from keybert) (13.7.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.4.0->keybert) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.4.0->keybert) (2.16.1)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.22.2->keybert) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.22.2->keybert) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.22.2->keybert) (3.3.0)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.32.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=0.3.8->keybert) (4.38.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=0.3.8->keybert) (4.66.2)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=0.3.8->keybert) (2.2.1+cu121)\n",
            "Requirement already satisfied: huggingface-hub>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=0.3.8->keybert) (0.20.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=0.3.8->keybert) (9.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers>=0.3.8->keybert) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers>=0.3.8->keybert) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers>=0.3.8->keybert) (2.31.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers>=0.3.8->keybert) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers>=0.3.8->keybert) (4.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers>=0.3.8->keybert) (24.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.4.0->keybert) (0.1.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (3.1.3)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (12.4.99)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers>=0.3.8->keybert) (2023.12.25)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers>=0.3.8->keybert) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers>=0.3.8->keybert) (0.4.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers>=0.3.8->keybert) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers>=0.3.8->keybert) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers>=0.3.8->keybert) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers>=0.3.8->keybert) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (1.3.0)\n",
            "Building wheels for collected packages: keybert\n",
            "  Building wheel for keybert (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keybert: filename=keybert-0.8.4-py3-none-any.whl size=39200 sha256=d0b984bfb2d53ecdaac8e4bf9f23d821dc9b79d9296cb5930817041c9d5a8906\n",
            "  Stored in directory: /root/.cache/pip/wheels/97/ef/4c/6588bd7072b0cc04225b40e639b991e49ebd4e21fb81f0acee\n",
            "Successfully built keybert\n",
            "Installing collected packages: keybert\n",
            "Successfully installed keybert-0.8.4\n",
            "Collecting keyphrase-vectorizers\n",
            "  Downloading keyphrase_vectorizers-0.0.11-py3-none-any.whl (29 kB)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from keyphrase-vectorizers) (1.25.2)\n",
            "Requirement already satisfied: spacy>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from keyphrase-vectorizers) (3.7.4)\n",
            "Collecting spacy-transformers>=1.1.6 (from keyphrase-vectorizers)\n",
            "  Downloading spacy_transformers-1.3.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (197 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m197.9/197.9 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nltk>=3.6.1 in /usr/local/lib/python3.10/dist-packages (from keyphrase-vectorizers) (3.8.1)\n",
            "Requirement already satisfied: scikit-learn>=1.0 in /usr/local/lib/python3.10/dist-packages (from keyphrase-vectorizers) (1.2.2)\n",
            "Requirement already satisfied: scipy>=1.7.3 in /usr/local/lib/python3.10/dist-packages (from keyphrase-vectorizers) (1.11.4)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from keyphrase-vectorizers) (5.9.5)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>=3.6.1->keyphrase-vectorizers) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>=3.6.1->keyphrase-vectorizers) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>=3.6.1->keyphrase-vectorizers) (2023.12.25)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk>=3.6.1->keyphrase-vectorizers) (4.66.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0->keyphrase-vectorizers) (3.3.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.0.1->keyphrase-vectorizers) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.0.1->keyphrase-vectorizers) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.0.1->keyphrase-vectorizers) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.0.1->keyphrase-vectorizers) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.0.1->keyphrase-vectorizers) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.0.1->keyphrase-vectorizers) (8.2.3)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.0.1->keyphrase-vectorizers) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.0.1->keyphrase-vectorizers) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.0.1->keyphrase-vectorizers) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.0.1->keyphrase-vectorizers) (0.3.4)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.0.1->keyphrase-vectorizers) (0.9.0)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.0.1->keyphrase-vectorizers) (6.4.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.0.1->keyphrase-vectorizers) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.0.1->keyphrase-vectorizers) (2.6.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.0.1->keyphrase-vectorizers) (3.1.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy>=3.0.1->keyphrase-vectorizers) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.0.1->keyphrase-vectorizers) (24.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.0.1->keyphrase-vectorizers) (3.3.0)\n",
            "Collecting transformers<4.37.0,>=3.4.0 (from spacy-transformers>=1.1.6->keyphrase-vectorizers)\n",
            "  Downloading transformers-4.36.2-py3-none-any.whl (8.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.2/8.2 MB\u001b[0m \u001b[31m34.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from spacy-transformers>=1.1.6->keyphrase-vectorizers) (2.2.1+cu121)\n",
            "Collecting spacy-alignments<1.0.0,>=0.7.2 (from spacy-transformers>=1.1.6->keyphrase-vectorizers)\n",
            "  Downloading spacy_alignments-0.9.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (313 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m314.0/314.0 kB\u001b[0m \u001b[31m30.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=3.0.1->keyphrase-vectorizers) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=3.0.1->keyphrase-vectorizers) (2.16.3)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=3.0.1->keyphrase-vectorizers) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3.0.1->keyphrase-vectorizers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3.0.1->keyphrase-vectorizers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3.0.1->keyphrase-vectorizers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3.0.1->keyphrase-vectorizers) (2024.2.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy>=3.0.1->keyphrase-vectorizers) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy>=3.0.1->keyphrase-vectorizers) (0.1.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->spacy-transformers>=1.1.6->keyphrase-vectorizers) (3.13.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->spacy-transformers>=1.1.6->keyphrase-vectorizers) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->spacy-transformers>=1.1.6->keyphrase-vectorizers) (3.2.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->spacy-transformers>=1.1.6->keyphrase-vectorizers) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->spacy-transformers>=1.1.6->keyphrase-vectorizers) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->spacy-transformers>=1.1.6->keyphrase-vectorizers) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->spacy-transformers>=1.1.6->keyphrase-vectorizers) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->spacy-transformers>=1.1.6->keyphrase-vectorizers) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->spacy-transformers>=1.1.6->keyphrase-vectorizers) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->spacy-transformers>=1.1.6->keyphrase-vectorizers) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->spacy-transformers>=1.1.6->keyphrase-vectorizers) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->spacy-transformers>=1.1.6->keyphrase-vectorizers) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->spacy-transformers>=1.1.6->keyphrase-vectorizers) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->spacy-transformers>=1.1.6->keyphrase-vectorizers) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->spacy-transformers>=1.1.6->keyphrase-vectorizers) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->spacy-transformers>=1.1.6->keyphrase-vectorizers) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.8.0->spacy-transformers>=1.1.6->keyphrase-vectorizers) (12.4.99)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers<4.37.0,>=3.4.0->spacy-transformers>=1.1.6->keyphrase-vectorizers) (0.20.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers<4.37.0,>=3.4.0->spacy-transformers>=1.1.6->keyphrase-vectorizers) (6.0.1)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers<4.37.0,>=3.4.0->spacy-transformers>=1.1.6->keyphrase-vectorizers) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers<4.37.0,>=3.4.0->spacy-transformers>=1.1.6->keyphrase-vectorizers) (0.4.2)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.4.0,>=0.1.0->spacy>=3.0.1->keyphrase-vectorizers) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy>=3.0.1->keyphrase-vectorizers) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->spacy-transformers>=1.1.6->keyphrase-vectorizers) (1.3.0)\n",
            "Installing collected packages: spacy-alignments, transformers, spacy-transformers, keyphrase-vectorizers\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.38.2\n",
            "    Uninstalling transformers-4.38.2:\n",
            "      Successfully uninstalled transformers-4.38.2\n",
            "Successfully installed keyphrase-vectorizers-0.0.11 spacy-alignments-0.9.1 spacy-transformers-1.3.4 transformers-4.36.2\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.36.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install BERTopic\n",
        "!pip install keybert\n",
        "!pip install keyphrase-vectorizers\n",
        "!python -m pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "qFxp9b-qcw8o"
      },
      "outputs": [],
      "source": [
        "from keyphrase_vectorizers import KeyphraseCountVectorizer\n",
        "from bertopic import BERTopic\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from nltk.corpus import stopwords\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from umap import UMAP\n",
        "from hdbscan import HDBSCAN\n",
        "from bertopic import BERTopic\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from bertopic.vectorizers import ClassTfidfTransformer\n",
        "from bertopic.representation import KeyBERTInspired, PartOfSpeech, MaximalMarginalRelevance\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import spacy\n",
        "import re\n",
        "from string import punctuation\n",
        "import transformers\n",
        "from bertopic.representation import TextGeneration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OfR6J_P2dLeH",
        "outputId": "f8a063d6-0aa4-4c8a-e8b1-2ea6d7d662c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "stopwords = list(stopwords.words('english')) + ['http', 'https', 'amp', 'com','XX','XXXX','XXX','XXXXX','00'\n",
        ",'xx','xxxx','xxx','xxxxx']\n",
        "vectorizer_model=KeyphraseCountVectorizer(stop_words=stopwords)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "LIvNYDGGdB_k"
      },
      "outputs": [],
      "source": [
        "df_complaints=pd.read_csv('../drive/MyDrive/Colab Notebooks/Complaint/complaints.csv',low_memory=False)\n",
        "desc_col='Consumer complaint narrative'\n",
        "\n",
        "df_complaints['Year']=pd.to_datetime(df_complaints['Date received']) .dt.year\n",
        "df_complaints['Month']=pd.to_datetime(df_complaints['Date received']) .dt.month\n",
        "df_complaints['Day']=pd.to_datetime(df_complaints['Date received']) .dt.day\n",
        "\n",
        "def clean(text):\n",
        "  #very light data cleansing\n",
        "    #remove @ppl, url\n",
        "\n",
        "    output = re.sub(r'https://\\S*','', text)\n",
        "    output = re.sub(r'@\\S*','',output)\n",
        "\n",
        "    #remove \\r, \\n\n",
        "    rep = r'|'.join((r'\\r',r'\\n'))\n",
        "    output = re.sub(rep,'',output)\n",
        "\n",
        "    # rep_covid = r'|'.join((r'\\W*covid\\S*',r'\\W*COVID\\S*',r'\\W*coronavirus\\S*', r'\\W*Covid\\S*',r'\\W*Coronavirus\\S*'))\n",
        "    # output = re.sub(rep_covid,'', output)\n",
        "\n",
        "    rep_covid = r'|'.join((r'\\W*XX\\S*',r'\\W*XXX\\S*',r'\\W*XXXX\\S*', r'\\W*XXXXX\\S*',r'\\W*XXXXXX\\S*',r'\\W*00\\S*'))\n",
        "    output = re.sub(rep_covid,'', output)\n",
        "\n",
        "    #remove duplicated punctuation\n",
        "    output = re.sub(r'([!()\\-{};:,<>./?@#$%\\^&*_~]){2,}', lambda x: x.group()[0], output)\n",
        "\n",
        "    #remove extra space\n",
        "    output = re.sub(r'\\s+', ' ', output).strip()\n",
        "\n",
        "    #remove string if string only contains punctuation\n",
        "    if sum([i.isalpha() for i in output])== 0:\n",
        "        output = ''\n",
        "\n",
        "    #remove string if length<5\n",
        "    if len(output.split()) < 5:\n",
        "        output = ''\n",
        "\n",
        "    return output#.lower()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qET_9K7SuB0D"
      },
      "source": [
        "First, the amount of datapoint classified as outliers is handled by the min_samples parameters in HDBSCAN. This value is automatically set to the same value of min_cluster_size. However, you can set it independently if you want to reduce the number of generated outliers. Lowering this value will result in less noise being generated.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "g3JbEu32--k5"
      },
      "outputs": [],
      "source": [
        "from bertopic.representation._base import BaseRepresentation\n",
        "import typing\n",
        "from typing import *\n",
        "from tqdm import tqdm\n",
        "from transformers import pipeline\n",
        "\n",
        "class CustomRepresentationModel(BaseRepresentation):\n",
        "    def __init__(self,\n",
        "                 model: Union[str, pipeline],\n",
        "                 prompt: str = None,\n",
        "                 pipeline_kwargs: Mapping[str, Any] = {},\n",
        "                 random_state: int = 42,\n",
        "                 nr_docs: int = 4,\n",
        "                 diversity: float = None,\n",
        "                 doc_length: int = None,\n",
        "                 tokenizer: Union[str, Callable] = None,\n",
        "                 task: str='text-generation',\n",
        "                 max_new_tokens: int=10\n",
        "                 ):\n",
        "        transformers.set_seed(random_state)\n",
        "        # if isinstance(model, str):\n",
        "        #     self.model = pipeline(\"text-generation\", model=model)\n",
        "        # elif isinstance(model, Pipeline):\n",
        "        #     self.model = model\n",
        "        # else:\n",
        "        #     raise ValueError(\"Make sure that the HF model that you\"\n",
        "        #                      \"pass is either a string referring to a\"\n",
        "        #                      \"HF model or a `transformers.pipeline` object.\")\n",
        "\n",
        "        if isinstance(model, str):\n",
        "            self.model = pipeline(\"text-generation\", model=model)\n",
        "        else :\n",
        "            self.model = transformers.pipeline(\n",
        "                        model=model, tokenizer=tokenizer,\n",
        "                        task=task,\n",
        "                        temperature=0.1,\n",
        "                        max_new_tokens=max_new_tokens,\n",
        "                        repetition_penalty=1.1\n",
        "                    )\n",
        "\n",
        "        self.DEFAULT_PROMPT=\"\"\n",
        "        self.prompt = prompt if prompt is not None else self.DEFAULT_PROMPT\n",
        "        self.default_prompt_ = self.DEFAULT_PROMPT\n",
        "        self.pipeline_kwargs = pipeline_kwargs\n",
        "        self.nr_docs = nr_docs\n",
        "        self.diversity = diversity\n",
        "        self.doc_length = doc_length\n",
        "        self.tokenizer = tokenizer\n",
        "        self.prompts_ = []\n",
        "\n",
        "\n",
        "    def _truncate_document(self,topic_model, doc_length, tokenizer, document: str):\n",
        "        \"\"\" Truncate a document to a certain length\n",
        "\n",
        "        If you want to add a custom tokenizer, then it will need to have a `decode` and\n",
        "        `encode` method. An example would be the following custom tokenizer:\n",
        "\n",
        "        ```python\n",
        "        class Tokenizer:\n",
        "            'A custom tokenizer that splits on commas'\n",
        "            def encode(self, doc):\n",
        "                return doc.split(\",\")\n",
        "\n",
        "            def decode(self, doc_chuncks):\n",
        "                return \",\".join(doc_chuncks)\n",
        "        ```\n",
        "\n",
        "        You can use this tokenizer by passing it to the `tokenizer` parameter.\n",
        "\n",
        "        Arguments:\n",
        "            topic_model: A BERTopic model\n",
        "            doc_length: The maximum length of each document. If a document is longer,\n",
        "                        it will be truncated. If None, the entire document is passed.\n",
        "            tokenizer: The tokenizer used to calculate to split the document into segments\n",
        "                      used to count the length of a document.\n",
        "                          * If tokenizer is 'char', then the document is split up\n",
        "                            into characters which are counted to adhere to `doc_length`\n",
        "                          * If tokenizer is 'whitespace', the document is split up\n",
        "                            into words separated by whitespaces. These words are counted\n",
        "                            and truncated depending on `doc_length`\n",
        "                          * If tokenizer is 'vectorizer', then the internal CountVectorizer\n",
        "                            is used to tokenize the document. These tokens are counted\n",
        "                            and trunctated depending on `doc_length`. They are decoded with\n",
        "                            whitespaces.\n",
        "                          * If tokenizer is a callable, then that callable is used to tokenize\n",
        "                            the document. These tokens are counted and truncated depending\n",
        "                            on `doc_length`\n",
        "            document: A single document\n",
        "\n",
        "        Returns:\n",
        "            truncated_document: A truncated document\n",
        "        \"\"\"\n",
        "        if doc_length is not None:\n",
        "            if tokenizer == \"char\":\n",
        "                truncated_document = document[:doc_length]\n",
        "            elif tokenizer == \"whitespace\":\n",
        "                truncated_document = \" \".join(document.split()[:doc_length])\n",
        "            elif tokenizer == \"vectorizer\":\n",
        "                tokenizer = topic_model.vectorizer_model.build_tokenizer()\n",
        "                truncated_document = \" \".join(tokenizer(document)[:doc_length])\n",
        "            elif hasattr(tokenizer, 'encode') and hasattr(tokenizer, 'decode'):\n",
        "                encoded_document = tokenizer.encode(document)\n",
        "                truncated_document = tokenizer.decode(encoded_document[:doc_length])\n",
        "            return truncated_document\n",
        "        #print(document)\n",
        "        return document\n",
        "\n",
        "    def extract_topics(self, topic_model, documents, c_tf_idf, topics\n",
        "                      ) -> Mapping[str, List[Tuple[str, float]]]:\n",
        "        \"\"\" Extract topics\n",
        "\n",
        "        Arguments:\n",
        "            topic_model: The BERTopic model\n",
        "            documents: A dataframe of documents with their related topics\n",
        "            c_tf_idf: The c-TF-IDF matrix\n",
        "            topics: The candidate topics as calculated with c-TF-IDF\n",
        "\n",
        "        Returns:\n",
        "            updated_topics: Updated topic representations\n",
        "        \"\"\"\n",
        "\n",
        "        # Extract the top 4 representative documents per topic\n",
        "        #if self.prompt != DEFAULT_PROMPT and \"[DOCUMENTS]\" in self.prompt:\n",
        "        repr_docs_mappings, _, _, _ = topic_model._extract_representative_docs(\n",
        "                c_tf_idf,\n",
        "                documents,\n",
        "                topics,\n",
        "                500,\n",
        "                self.nr_docs,\n",
        "                self.diversity\n",
        "            )\n",
        "        #else:\n",
        "\n",
        "        #repr_docs_mappings = {topic: None for topic in topics.keys()}\n",
        "\n",
        "\n",
        "\n",
        "        updated_topics = {}\n",
        "        for topic, docs in tqdm(repr_docs_mappings.items(), disable=not topic_model.verbose):\n",
        "            # Prepare prompt\n",
        "            truncated_docs = [self._truncate_document(topic_model, self.doc_length, self.tokenizer, doc) for doc in docs]\n",
        "            prompt = self._create_prompt(truncated_docs, topic, topics)\n",
        "            self.prompts_.append(prompt)\n",
        "\n",
        "            # Extract result from generator and use that as label\n",
        "            topic_description = self.model(prompt, **self.pipeline_kwargs)\n",
        "\n",
        "            topic_description = [(description[\"generated_text\"].replace(prompt, \"\"), 1) for description in topic_description]\n",
        "\n",
        "\n",
        "            # if len(topic_description) < 10:\n",
        "            #     topic_description += [(\"\", 0) for _ in range(10-len(topic_description))]\n",
        "\n",
        "\n",
        "            updated_topics[topic] = topic_description[0]\n",
        "\n",
        "        return updated_topics\n",
        "\n",
        "    def _create_prompt(self, docs, topic, topics):\n",
        "\n",
        "        keywords = \", \".join(list(zip(*topics[topic]))[0])\n",
        "        DEFAULT_PROMPT=\"\"\n",
        "        # Use the default prompt and replace keywords\n",
        "        if self.prompt == DEFAULT_PROMPT:\n",
        "            prompt = self.prompt.replace(\"[KEYWORDS]\", keywords)\n",
        "\n",
        "        # Use a prompt that leverages either keywords or documents in\n",
        "        # a custom location\n",
        "        else:\n",
        "            prompt = self.prompt\n",
        "            if \"[KEYWORDS]\" in prompt:\n",
        "                prompt = prompt.replace(\"[KEYWORDS]\", keywords)\n",
        "            if \"[DOCUMENTS]\" in prompt:\n",
        "                to_replace = \"\"\n",
        "                for doc in docs:\n",
        "                    to_replace += f\"- {doc}\\n\"\n",
        "                prompt = prompt.replace(\"[DOCUMENTS]\", to_replace)\n",
        "\n",
        "        return prompt\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "PaXsTohudYHM"
      },
      "outputs": [],
      "source": [
        "# we add this to remove stopwords that can pollute topcs\n",
        "#vectorizer_model = CountVectorizer(ngram_range=(1, 2), stop_words=stopwords)\n",
        "vectorizer_model=KeyphraseCountVectorizer(stop_words=stopwords)\n",
        "\n",
        "\n",
        "# embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "# umap_model = UMAP(n_neighbors=3, n_components=100, min_dist=0.05)\n",
        "# hdbscan_model = HDBSCAN(min_cluster_size=10, min_samples=5,\n",
        "#                         gen_min_span_tree=True,\n",
        "#                         prediction_data=True)\n",
        "\n",
        "# representation_model = MaximalMarginalRelevance(diversity=0.2)\n",
        "# ctfidf_model = ClassTfidfTransformer(reduce_frequent_words=True)\n",
        "\n",
        "\n",
        "# we add this to remove stopwords that can pollute topcs\n",
        "vectorizer_model = CountVectorizer(ngram_range=(1, 2), stop_words=stopwords)\n",
        "vectorizer_model=KeyphraseCountVectorizer(stop_words=stopwords,pos_pattern=\"<N.*>+<J.*>*\")\n",
        "\n",
        "\n",
        "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "umap_model = UMAP(n_neighbors=5, n_components=100, min_dist=0.05,\n",
        "                        random_state=42)\n",
        "hdbscan_model = HDBSCAN(min_cluster_size=20, min_samples=3,\n",
        "                        gen_min_span_tree=True,\n",
        "                        prediction_data=True)\n",
        "\n",
        "ctfidf_model = ClassTfidfTransformer(reduce_frequent_words=True)\n",
        "\n",
        "#cluster_model = KMeans(n_clusters=50)\n",
        "\n",
        "\n",
        "mmr = MaximalMarginalRelevance(diversity=0.2)\n",
        "kb_mmr = [KeyBERTInspired(top_n_words=30),\n",
        "                                MaximalMarginalRelevance(diversity=.5)]\n",
        "\n",
        "pos_patterns = [\n",
        "            [{'POS': 'ADJ'}, {'POS': 'NOUN'}],\n",
        "            [{'POS': 'NOUN'}], [{'POS': 'ADJ'}],\n",
        "             [{'POS': '<N.*>+<J.*>*'}]\n",
        "             ]\n",
        "\n",
        "post = PartOfSpeech(\"en_core_web_sm\", pos_patterns=pos_patterns)\n",
        "\n",
        "# Create your representation model in gpt2\n",
        " # Llama 2 Tokenizer\n",
        "model_id='gpt2'\n",
        "tokenizer = transformers.AutoTokenizer.from_pretrained(model_id)\n",
        "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
        "# Llama 2 Model\n",
        "model = transformers.AutoModelForCausalLM.from_pretrained(\n",
        "    model_id,\n",
        "    trust_remote_code=True\n",
        "\n",
        ")\n",
        "p=TextGeneration('gpt2').default_prompt_\n",
        "\n",
        "#p=\"I have a topic described by the following keywords: [KEYWORDS]. The name of this topic is \"\n",
        "# p=f\"\"\"\n",
        "# I have a topic described by the following keywords: [KEYWORDS].\n",
        "# The name of this topic is:\n",
        "# \"\"\"\n",
        "gptrep =CustomRepresentationModel(model=model,tokenizer=tokenizer,prompt=p,task='text-generation',max_new_tokens=10)\n",
        "\n",
        "\n",
        "####\n",
        "prompt = \"\\n I have a topic described by the following keywords: [KEYWORDS].\\nBased on the previous keywords, this topic is about \"\n",
        "\n",
        "# Create your representation model\n",
        "# generator = transformers.pipeline('text2text-generation', model='google/flan-t5-base')\n",
        "# flnrep= TextGeneration(model=generator,prompt=prompt, tokenizer = generator.tokenizer, doc_length=510)\n",
        "model_id='google/flan-t5-base'\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, AutoModelForSeq2SeqLM\n",
        "\n",
        "checkpoint = \"google/flan-t5-base\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(checkpoint)\n",
        "\n",
        "flnrep=CustomRepresentationModel(model=model,tokenizer=tokenizer,prompt=prompt,task='text2text-generation',max_new_tokens=10)\n",
        "#\n",
        "representation_model={\n",
        "    'mmr':mmr,\n",
        "    'kb_mmr':kb_mmr,\n",
        "    'post':post#,\n",
        "   # 'gptrep':gptrep,\n",
        "   # 'flnrep':flnrep\n",
        "\n",
        "}\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YsKnCpFJiOVn",
        "outputId": "d1a1624d-40b8-4f49-a86a-808a6b6ce494"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2000"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "topic_model = BERTopic(\n",
        "    umap_model=umap_model,\n",
        "    hdbscan_model=hdbscan_model,\n",
        "    embedding_model=embedding_model,\n",
        "    vectorizer_model=vectorizer_model,\n",
        "    top_n_words=10,\n",
        "    language='english',\n",
        "    calculate_probabilities=True,\n",
        "    verbose=True,\n",
        "    nr_topics='auto',\n",
        "    ctfidf_model=ctfidf_model,\n",
        "    representation_model=representation_model\n",
        ")\n",
        "df_complaints=df_complaints[df_complaints['Year']==2024]\n",
        "data=df_complaints[df_complaints['Year']==2024]\n",
        "data=data.sample(2000)\n",
        "#data=data[data['Month']==1]\n",
        "#data=data[data['Day'].isin([1,2,3,4])]\n",
        "data[desc_col]=data[desc_col].apply(clean)\n",
        "data=list(data[desc_col])\n",
        "len(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DfWaXoaMuPGj"
      },
      "source": [
        "Second, after training our BERTopic model, we can assign outliers to topics by making use of the .reduce_outliers function in BERTopic. An advantage of using this approach is that there are four built in strategies one can choose for reducing outliers. Moreover, this technique allows the user to experiment with reducing outliers across a number of strategies and parameters without actually having to re-train the topic model each time. You can learn more about the .reduce_outlier function here. The following is a minimal example of how to use this function:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292,
          "referenced_widgets": [
            "13989205888a4e1292bafe0c34520eaf",
            "82586ea9dc16408e930b56f75916f2af",
            "e9e9d842cad64e4f966a7130e1d97773",
            "6d9a77f7f608408abc5493e0a83a2633",
            "16b34c22c6f24be9989543235efb4711",
            "40c54b5e80cd424289ea3e3a929cd667",
            "cb6c63fa7d8347739538405e5022c30a",
            "e7d206e9c5004cc6ae1caad37fc80a9f",
            "bbe82e9ccb0d431ba18b3854a1480473",
            "7bc8ccd7dc734b1ab1e9895dc2795e1e",
            "096bc8f572194e4a9c88a00589ccf754"
          ]
        },
        "id": "TEgiA10foDMJ",
        "outputId": "702ef2a2-ac7a-402b-ba35-5b161b457ec4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024-03-21 06:41:51,934 - BERTopic - Embedding - Transforming documents to embeddings.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/63 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "13989205888a4e1292bafe0c34520eaf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024-03-21 06:46:50,732 - BERTopic - Embedding - Completed ✓\n",
            "2024-03-21 06:46:50,736 - BERTopic - Dimensionality - Fitting the dimensionality reduction algorithm\n",
            "2024-03-21 06:47:02,588 - BERTopic - Dimensionality - Completed ✓\n",
            "2024-03-21 06:47:02,591 - BERTopic - Cluster - Start clustering the reduced embeddings\n",
            "2024-03-21 06:47:03,739 - BERTopic - Cluster - Completed ✓\n",
            "2024-03-21 06:47:03,741 - BERTopic - Representation - Extracting topics from clusters using representation models.\n",
            "/usr/local/lib/python3.10/dist-packages/bertopic/vectorizers/_ctfidf.py:82: RuntimeWarning: divide by zero encountered in divide\n",
            "  idf = np.log((avg_nr_samples / df)+1)\n",
            "2024-03-21 06:50:16,980 - BERTopic - Representation - Completed ✓\n",
            "2024-03-21 06:50:16,982 - BERTopic - Topic reduction - Reducing number of topics\n",
            "/usr/local/lib/python3.10/dist-packages/bertopic/vectorizers/_ctfidf.py:82: RuntimeWarning: divide by zero encountered in divide\n",
            "  idf = np.log((avg_nr_samples / df)+1)\n",
            "2024-03-21 06:52:31,986 - BERTopic - Topic reduction - Reduced number of topics from 29 to 6\n"
          ]
        }
      ],
      "source": [
        "topics, probs = topic_model.fit_transform(data)\n",
        "# Reduce outliers\n",
        "#new_topics = model.reduce_outliers(docs, topics, probabilities=probs, strategy=\"probabilities\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QZCDCd6JuoRS"
      },
      "source": [
        "Third, we can replace HDBSCAN with any other clustering algorithm that we want. So we can choose a clustering algorithm, like k-Means, that does not produce any outliers at all. Using k-Means instead of HDBSCAN is straightforward:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Method 3 - pickle\n",
        "topic_model.save('../drive/MyDrive/Colab Notebooks/Complaint/topic_model.csv', serialization=\"pickle\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GQotxpVWyB14",
        "outputId": "75bce5c2-7c47-4c88-c63b-31116c8a2123"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024-03-21 06:52:44,615 - BERTopic - WARNING: When you use `pickle` to save/load a BERTopic model,please make sure that the environments in which you saveand load the model are **exactly** the same. The version of BERTopic,its dependencies, and python need to remain the same.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BveSk4c8umvE"
      },
      "outputs": [],
      "source": [
        "# cluster_model = KMeans(n_clusters=50)\n",
        "# topic_model = BERTopic(hdbscan_model=cluster_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "MgKMyMX9wNKY"
      },
      "outputs": [],
      "source": [
        "new_topics = topic_model.reduce_outliers(list(data), topics, probabilities=probs, strategy=\"probabilities\")\n",
        "l=pd.DataFrame({'a':new_topics,'b':topics})\n",
        "l.to_csv('../drive/MyDrive/Colab Notebooks/Complaint/l.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "DyONsAcdOuDT"
      },
      "outputs": [],
      "source": [
        "x=topic_info=topic_model.get_topic_info()\n",
        "\n",
        "try:\n",
        "  print(list(x['flnrep']))\n",
        "  print(set(x['gptrep']))\n",
        "except:\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "topic_info"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 342
        },
        "id": "wKyyJGv2vEa_",
        "outputId": "1f8ecda0-5c26-4ee7-a907-3644e94c57bf"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Topic  Count                                           Name  \\\n",
              "0     -1    373                -1_delete_account_please_credit   \n",
              "1      0   1119           0_consumer_report_information_credit   \n",
              "2      1    408                 1_wells_fargo_wells fargo_bank   \n",
              "3      2     52    2_experian_lie_complaint_fraudulent company   \n",
              "4      3     25        3_on time_update_payments_time payments   \n",
              "5      4     23  4_interest_balance_statement_balance transfer   \n",
              "\n",
              "                                      Representation  \\\n",
              "0  [delete, account, please, credit, card, bank, ...   \n",
              "1  [consumer, report, information, credit, report...   \n",
              "2  [wells, fargo, wells fargo, bank, account, car...   \n",
              "3  [experian, lie, complaint, fraudulent company,...   \n",
              "4  [on time, update, payments, time payments, my ...   \n",
              "5  [interest, balance, statement, balance transfe...   \n",
              "\n",
              "                                                 mmr  \\\n",
              "0  [delete, account, please, credit, card, bank, ...   \n",
              "1  [consumer, report, information, credit, report...   \n",
              "2  [wells, fargo, wells fargo, bank, account, car...   \n",
              "3  [experian, lie, complaint, fraudulent company,...   \n",
              "4  [on time, update, payments, time payments, my ...   \n",
              "5  [interest, balance, statement, balance transfe...   \n",
              "\n",
              "                                              kb_mmr  \\\n",
              "0  [my credit report, original creditor, consumer...   \n",
              "1  [fair credit reporting act, my credit report, ...   \n",
              "2  [fraud, refund, fargo, complaint, charges, che...   \n",
              "3  [credit reporting act experian, others complai...   \n",
              "4  [late payment, account incorrect name, synchro...   \n",
              "5  [interest payment, credit card statement, paym...   \n",
              "\n",
              "                                                post  \\\n",
              "0  [account, credit, card, bank, color, usc, copy...   \n",
              "1  [consumer, report, information, credit, report...   \n",
              "2  [fargo, bank, account, card, money, back, frau...   \n",
              "3  [experian, lie, complaint, fraudulent company,...   \n",
              "4  [payments, sleep, incorrect, history, stress, ...   \n",
              "5  [interest, balance, statement, pay, rate, mont...   \n",
              "\n",
              "                                 Representative_Docs  \n",
              "0  [On I concluded a lease trade-in for my accoun...  \n",
              "1  [According to the Fair Credit Reporting Act se...  \n",
              "2  [On the we noticed a large drop in our balance...  \n",
              "3  [I am writing to address a critical matter con...  \n",
              "4  [Please update my account and remove the inacc...  \n",
              "5  [Synchrony Bank intentionally uses misleading ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-48e4bf68-ca40-4121-ba5f-796b8f55f256\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Topic</th>\n",
              "      <th>Count</th>\n",
              "      <th>Name</th>\n",
              "      <th>Representation</th>\n",
              "      <th>mmr</th>\n",
              "      <th>kb_mmr</th>\n",
              "      <th>post</th>\n",
              "      <th>Representative_Docs</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-1</td>\n",
              "      <td>373</td>\n",
              "      <td>-1_delete_account_please_credit</td>\n",
              "      <td>[delete, account, please, credit, card, bank, ...</td>\n",
              "      <td>[delete, account, please, credit, card, bank, ...</td>\n",
              "      <td>[my credit report, original creditor, consumer...</td>\n",
              "      <td>[account, credit, card, bank, color, usc, copy...</td>\n",
              "      <td>[On I concluded a lease trade-in for my accoun...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1119</td>\n",
              "      <td>0_consumer_report_information_credit</td>\n",
              "      <td>[consumer, report, information, credit, report...</td>\n",
              "      <td>[consumer, report, information, credit, report...</td>\n",
              "      <td>[fair credit reporting act, my credit report, ...</td>\n",
              "      <td>[consumer, report, information, credit, report...</td>\n",
              "      <td>[According to the Fair Credit Reporting Act se...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>408</td>\n",
              "      <td>1_wells_fargo_wells fargo_bank</td>\n",
              "      <td>[wells, fargo, wells fargo, bank, account, car...</td>\n",
              "      <td>[wells, fargo, wells fargo, bank, account, car...</td>\n",
              "      <td>[fraud, refund, fargo, complaint, charges, che...</td>\n",
              "      <td>[fargo, bank, account, card, money, back, frau...</td>\n",
              "      <td>[On the we noticed a large drop in our balance...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>52</td>\n",
              "      <td>2_experian_lie_complaint_fraudulent company</td>\n",
              "      <td>[experian, lie, complaint, fraudulent company,...</td>\n",
              "      <td>[experian, lie, complaint, fraudulent company,...</td>\n",
              "      <td>[credit reporting act experian, others complai...</td>\n",
              "      <td>[experian, lie, complaint, fraudulent company,...</td>\n",
              "      <td>[I am writing to address a critical matter con...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>25</td>\n",
              "      <td>3_on time_update_payments_time payments</td>\n",
              "      <td>[on time, update, payments, time payments, my ...</td>\n",
              "      <td>[on time, update, payments, time payments, my ...</td>\n",
              "      <td>[late payment, account incorrect name, synchro...</td>\n",
              "      <td>[payments, sleep, incorrect, history, stress, ...</td>\n",
              "      <td>[Please update my account and remove the inacc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>4</td>\n",
              "      <td>23</td>\n",
              "      <td>4_interest_balance_statement_balance transfer</td>\n",
              "      <td>[interest, balance, statement, balance transfe...</td>\n",
              "      <td>[interest, balance, statement, balance transfe...</td>\n",
              "      <td>[interest payment, credit card statement, paym...</td>\n",
              "      <td>[interest, balance, statement, pay, rate, mont...</td>\n",
              "      <td>[Synchrony Bank intentionally uses misleading ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-48e4bf68-ca40-4121-ba5f-796b8f55f256')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-48e4bf68-ca40-4121-ba5f-796b8f55f256 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-48e4bf68-ca40-4121-ba5f-796b8f55f256');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-798a76eb-0d61-4bd7-8d3c-f271b8a95b2a\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-798a76eb-0d61-4bd7-8d3c-f271b8a95b2a')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-798a76eb-0d61-4bd7-8d3c-f271b8a95b2a button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_17ee5e2e-8f47-4dcf-a955-9fb910788b59\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('x')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_17ee5e2e-8f47-4dcf-a955-9fb910788b59 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('x');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "x",
              "summary": "{\n  \"name\": \"x\",\n  \"rows\": 6,\n  \"fields\": [\n    {\n      \"column\": \"Topic\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": -1,\n        \"max\": 4,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          -1,\n          0,\n          4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 423,\n        \"min\": 23,\n        \"max\": 1119,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          373,\n          1119,\n          23\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"-1_delete_account_please_credit\",\n          \"0_consumer_report_information_credit\",\n          \"4_interest_balance_statement_balance transfer\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Representation\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mmr\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"kb_mmr\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"post\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Representative_Docs\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cyLFP1-XYqk2",
        "outputId": "30693299-832b-483e-d063-df731f777d68"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**\n",
            "my credit report, original creditor, consumer reporting agency, account immediately, us bank, fraudulent, transactions, charges, reporting, violation\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('My Credit Report and Account', 1)]\n",
            "\n",
            "fair credit reporting act, my credit report, reporting agency, consumer reporting, identity theft, privacy, agencies, violations, accounts, my rights\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('Fair Credit Reporting Act (', 1)]\n",
            "\n",
            "fraud, refund, fargo, complaint, charges, checking account, citibank, department, wells, balance\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('\"Fraudulent Payment', 1)]\n",
            "\n",
            "credit reporting act experian, others complaint experian, experian fixed nothing, fraudulent fraudulent fraudulent fraudulent fraudulent fraudulent, complaint, phone number gor experian, creditors, predatory company still, bureau, investigation\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('\"credit reporting acts\".', 1)]\n",
            "\n",
            "late payment, account incorrect name, synchrony bank, delays, debit card, mortgage holder, incorrect nj pa, immediate action, online, fail\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('Late Payment - A short', 1)]\n",
            "\n",
            "interest payment, credit card statement, payment due date, statement balance, transaction fee, card balance, cash advance, charges, balance transfers, citibank\n",
            "[('Interest Payment and Credit Card', 1)]\n",
            "\n",
            "________________________\n",
            "**\n",
            "\n",
            " I have a topic described by the following keywords: my credit report, original creditor, consumer reporting agency, account immediately, us bank, fraudulent, transactions, charges, reporting, violation.\n",
            "Based on the previous keywords, this topic is about \n",
            "[('credit report - consumer reporting agency', 1)]\n",
            "\n",
            "\n",
            " I have a topic described by the following keywords: fair credit reporting act, my credit report, reporting agency, consumer reporting, identity theft, privacy, agencies, violations, accounts, my rights.\n",
            "Based on the previous keywords, this topic is about \n",
            "[('credit reporting agency', 1)]\n",
            "\n",
            "\n",
            " I have a topic described by the following keywords: fraud, refund, fargo, complaint, charges, checking account, citibank, department, wells, balance.\n",
            "Based on the previous keywords, this topic is about \n",
            "[('california bank charges for checking', 1)]\n",
            "\n",
            "\n",
            " I have a topic described by the following keywords: credit reporting act experian, others complaint experian, experian fixed nothing, fraudulent fraudulent fraudulent fraudulent fraudulent fraudulent, complaint, phone number gor experian, creditors, predatory company still, bureau, investigation.\n",
            "Based on the previous keywords, this topic is about \n",
            "[('credit reporting act', 1)]\n",
            "\n",
            "\n",
            " I have a topic described by the following keywords: late payment, account incorrect name, synchrony bank, delays, debit card, mortgage holder, incorrect nj pa, immediate action, online, fail.\n",
            "Based on the previous keywords, this topic is about \n",
            "[('nj pa account id incorrect name', 1)]\n",
            "\n",
            "\n",
            " I have a topic described by the following keywords: interest payment, credit card statement, payment due date, statement balance, transaction fee, card balance, cash advance, charges, balance transfers, citibank.\n",
            "Based on the previous keywords, this topic is about \n",
            "[('citibank statement balance', 1)]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "topic_info=topic_model.get_topic_info()\n",
        "\n",
        "# Create your representation model in gpt2\n",
        " # Llama 2 Tokenizer\n",
        "model_id='gpt2'\n",
        "tokenizer = transformers.AutoTokenizer.from_pretrained(model_id)\n",
        "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
        "# Llama 2 Model\n",
        "model = transformers.AutoModelForCausalLM.from_pretrained(\n",
        "    model_id,\n",
        "    trust_remote_code=True\n",
        "\n",
        ")\n",
        "prompt=TextGeneration('gpt2').default_prompt_\n",
        "\n",
        "\n",
        "task='text-generation'\n",
        "max_new_tokens=5\n",
        "\n",
        "pip = transformers.pipeline(\n",
        "                        model=model, tokenizer=tokenizer,\n",
        "                        task=task,\n",
        "                        temperature=0.1,\n",
        "                        max_new_tokens=max_new_tokens,\n",
        "                        repetition_penalty=1.1 ,\n",
        "                        penalty_alpha=0.6,\n",
        "                        top_k=4\n",
        "                    )\n",
        "\n",
        "print('**')\n",
        "for kb_mmr in topic_info['kb_mmr'] :\n",
        "\n",
        "    s=', '.join(kb_mmr)\n",
        "    p = prompt.replace(\"[KEYWORDS]\",  s)\n",
        "    print(s)\n",
        "    # Extract result from generator and use that as label\n",
        "    topic_description = pip(p )\n",
        "    topic_description = [(description[\"generated_text\"].replace(p, \"\"), 1) for description in topic_description]\n",
        "    print(topic_description)\n",
        "    print()\n",
        "\n",
        "#------------------\n",
        "\n",
        "\n",
        "print('________________________')\n",
        "\n",
        "\n",
        "####\n",
        "prompt = \"\\n I have a topic described by the following keywords: [KEYWORDS].\\nBased on the previous keywords, this topic is about \"\n",
        "\n",
        "# Create your representation model\n",
        "# generator = transformers.pipeline('text2text-generation', model='google/flan-t5-base')\n",
        "# flnrep= TextGeneration(model=generator,prompt=prompt, tokenizer = generator.tokenizer, doc_length=510)\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, AutoModelForSeq2SeqLM\n",
        "\n",
        "checkpoint = \"google/flan-t5-base\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(checkpoint)\n",
        "\n",
        "\n",
        "task='text2text-generation'\n",
        "max_new_tokens=10\n",
        "\n",
        "pip = transformers.pipeline(\n",
        "                        model=model, tokenizer=tokenizer,\n",
        "                        task=task,\n",
        "                        temperature=0.1,\n",
        "                        max_new_tokens=max_new_tokens,\n",
        "                        repetition_penalty=1.1 ,\n",
        "                        penalty_alpha=0.3,\n",
        "                        top_k=4\n",
        "                    )\n",
        "\n",
        "print('**')\n",
        "for kb_mmr in topic_info['kb_mmr'] :\n",
        "\n",
        "    s=', '.join(kb_mmr)\n",
        "    p = prompt.replace(\"[KEYWORDS]\",  s)\n",
        "    print(p)\n",
        "    # Extract result from generator and use that as label\n",
        "    topic_description = pip(p )\n",
        "    topic_description = [(description[\"generated_text\"].replace(p, \"\"), 1) for description in topic_description]\n",
        "    print(topic_description)\n",
        "    print()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RCdXhU157AjX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "Kug9ep_IY7tu"
      },
      "outputs": [],
      "source": [
        "x.to_csv('../drive/MyDrive/Colab Notebooks/Complaint/x.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kLxGsGkxicpB"
      },
      "outputs": [],
      "source": [
        "model.get_document_info(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "IA3x35TPfzF4"
      },
      "outputs": [],
      "source": [
        "model.get_document_info(data).to_csv('../drive/MyDrive/Colab Notebooks/Complaint/res1.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8axPYHtVsoVN"
      },
      "outputs": [],
      "source": [
        "import gensim.corpora as corpora\n",
        "from gensim.models.coherencemodel import CoherenceModel\n",
        "\n",
        "cv = topic_model.vectorizer_model\n",
        "X = cv.fit_transform(data)\n",
        "doc_tokens =  cv.inverse_transform(X)\n",
        "\n",
        "id2word = corpora.Dictionary(doc_tokens)\n",
        "texts = doc_tokens\n",
        "corpus = [id2word.doc2bow(text) for text in texts]\n",
        "\n",
        "topic_words = []\n",
        "for i in range(len(topic_model.get_topic_freq())-1):\n",
        "  interim = []\n",
        "  interim = [t[0] for t in model.get_topic(i)]\n",
        "  topic_words.append(interim)\n",
        "\n",
        "\n",
        "\n",
        "coherence_model = CoherenceModel(topics=topic_words,\n",
        "                                 texts=texts,\n",
        "                                 corpus=corpus,\n",
        "                                 dictionary=id2word,\n",
        "                                 coherence='c_v')\n",
        "coherence_model.get_coherence()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HrQvWydQoYj3"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "freq={}\n",
        "for doc in doc_tokens:\n",
        "   for token in doc:\n",
        "    if token in freq:\n",
        "        freq[token]=freq[token]+1\n",
        "    else:\n",
        "        freq[token]=1\n"
      ],
      "metadata": {
        "id": "f8KiYSqonXdT"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WF0GvFmQ3PEw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_token_frequency=pd.DataFrame(freq.items(), columns=['token', 'frequency'])\n",
        "#df_token_frequency.plot.bar(x='token', y='frequency', rot=0)"
      ],
      "metadata": {
        "id": "OuGlgwQMpdtY"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_token_frequency.sort_values('frequency',ascending=False)\n",
        "df_token_frequency[df_token_frequency['frequency']>100]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "COB1A-_trtI5",
        "outputId": "b516b238-ed5b-4077-da59-466456e6bccf"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [token, frequency]\n",
              "Index: []"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-abeba388-d580-47dc-bf06-870ca1d6b088\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>token</th>\n",
              "      <th>frequency</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-abeba388-d580-47dc-bf06-870ca1d6b088')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-abeba388-d580-47dc-bf06-870ca1d6b088 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-abeba388-d580-47dc-bf06-870ca1d6b088');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "repr_error": "Out of range float values are not JSON compliant: nan"
            }
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_token_frequency.to_csv('../drive/MyDrive/Colab Notebooks/Complaint/token_frequency.csv')"
      ],
      "metadata": {
        "id": "ddJfKZvrqYyl"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EeZw7oETscFV",
        "outputId": "21c6134f-f841-44a3-d75e-908aa4b1a619"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['balance transfers', 'credit balance refund', 'rates', ...,\n",
              "       'transaction account', 'affirmation', 'segment true'], dtype=object)"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.vectorizer_model.get_feature_names_out()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_44iwXuFs7l_"
      },
      "outputs": [],
      "source": [
        "topic_term_matrix = model.c_tf_idf_\n",
        "words =model.vectorizer_model.get_feature_names_out()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p3Xbpb49OkPY"
      },
      "outputs": [],
      "source": [
        "# # Extract keywords\n",
        "# from keybert import KeyBERT\n",
        "# kw_model = KeyBERT()\n",
        "# keywords = kw_model.extract_keywords(docs=list(data),vectorizer=vectorizer_model)\n",
        "\n",
        "# # Create our vocabulary\n",
        "# vocabulary = [k[0] for keyword in keywords for k in keyword]\n",
        "# vocabulary = list(set(vocabulary))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "freq={}\n",
        "doc_tokens=''\n",
        "df_token_frequency=''"
      ],
      "metadata": {
        "id": "A-StTZiqBHrI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "summarize"
      ],
      "metadata": {
        "id": "NPfOn7r67umK"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1yVUKX9-Lk9ZyBtYjAHptlZFa8v2hrTME",
      "authorship_tag": "ABX9TyO8dAPsRcYl61hr+jHVBNjA",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "13989205888a4e1292bafe0c34520eaf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_82586ea9dc16408e930b56f75916f2af",
              "IPY_MODEL_e9e9d842cad64e4f966a7130e1d97773",
              "IPY_MODEL_6d9a77f7f608408abc5493e0a83a2633"
            ],
            "layout": "IPY_MODEL_16b34c22c6f24be9989543235efb4711"
          }
        },
        "82586ea9dc16408e930b56f75916f2af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_40c54b5e80cd424289ea3e3a929cd667",
            "placeholder": "​",
            "style": "IPY_MODEL_cb6c63fa7d8347739538405e5022c30a",
            "value": "Batches: 100%"
          }
        },
        "e9e9d842cad64e4f966a7130e1d97773": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e7d206e9c5004cc6ae1caad37fc80a9f",
            "max": 63,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bbe82e9ccb0d431ba18b3854a1480473",
            "value": 63
          }
        },
        "6d9a77f7f608408abc5493e0a83a2633": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7bc8ccd7dc734b1ab1e9895dc2795e1e",
            "placeholder": "​",
            "style": "IPY_MODEL_096bc8f572194e4a9c88a00589ccf754",
            "value": " 63/63 [04:58&lt;00:00,  2.62it/s]"
          }
        },
        "16b34c22c6f24be9989543235efb4711": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "40c54b5e80cd424289ea3e3a929cd667": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cb6c63fa7d8347739538405e5022c30a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e7d206e9c5004cc6ae1caad37fc80a9f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bbe82e9ccb0d431ba18b3854a1480473": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7bc8ccd7dc734b1ab1e9895dc2795e1e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "096bc8f572194e4a9c88a00589ccf754": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}